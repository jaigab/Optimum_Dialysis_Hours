{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c12a43-a0e7-4c98-aecf-b19c570469c5",
   "metadata": {},
   "source": [
    "<h1> Tweet location predictor </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15285c6c-5f26-48a1-9b43-63b0d326834b",
   "metadata": {},
   "source": [
    "Import required python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1617d653-7c2c-45f3-8bdc-2ab463d96aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a689eb-ef91-4f51-afd4-e94dea33d82a",
   "metadata": {},
   "source": [
    "Import data tweets from 3 locations; New York, London, Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267d4ec7-67d2-4891-bf2c-124d27b187c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_york_tweets = pd.read_json(\"new_york.json\", lines = True)\n",
    "london_tweets = pd.read_json(\"london.json\", lines = True)\n",
    "paris_tweets = pd.read_json(\"paris.json\", lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367aba54-e7cd-439d-8fc0-f2179ba504bb",
   "metadata": {},
   "source": [
    "Turn the text of each dataframe of tweets from each city into a list of text values. <br>\n",
    "I then combined the lists and created an additional variable called \"labels\" to signify where each tweet is from in the master list \"all_tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59088478-7887-40c4-8a7d-04411bba97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_york_text = new_york_tweets[\"text\"].tolist()\n",
    "london_text = london_tweets[\"text\"].tolist()\n",
    "paris_text = paris_tweets[\"text\"].tolist()\n",
    "\n",
    "all_tweets = new_york_text + london_text + paris_text\n",
    "\n",
    "labels = [0] * len(new_york_text) + [1] * len(london_text) + [2] * len(paris_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7afc682-f063-459f-8769-2398bf1e03a4",
   "metadata": {},
   "source": [
    "I then split the tweets and labels into a training and testing set with a ratio of 4:1. <br>\n",
    "I then created a CountVectorizer object and used the .fit and .transform method to turn train_data and test_data into lists that count the number of times a word is in the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a1de4aa-c790-40e2-9871-8bca1531d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(all_tweets, labels, test_size = 0.2, random_state = 42)\n",
    "\n",
    "counter = CountVectorizer()\n",
    "counter.fit(train_data)\n",
    "train_counts = counter.transform(train_data)\n",
    "test_counts = counter.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed585e-961f-4734-8206-2a668fb5d5df",
   "metadata": {},
   "source": [
    "MultinomialNB object is created and trained using train_counts. This model is then used to predict labels for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "abafc27b-1ae0-4d8d-b8cd-9ed9e8199c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of this model is: 0.7145\n"
     ]
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_counts,train_labels)\n",
    "predictions = classifier.predict(test_counts)\n",
    "print(\"The accuracy score of this model is: {}\".format(round(accuracy_score(test_labels,predictions),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e51e80c-78f8-4aad-8305-157afe2856b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[607, 352,  12],\n",
       "       [204, 835,  28],\n",
       "       [ 30,  92, 355]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_confusion_matrix = confusion_matrix(test_labels,predictions)\n",
    "NB_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab7e66-1e0d-47b5-afbf-1b2da0da876b",
   "metadata": {},
   "source": [
    "I then created a function for using the model to predict where new tweets are from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33036284-1e13-4ed9-abb3-3cf972404f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_predict(tweet):\n",
    "    tweet_count = counter.transform([tweet])\n",
    "    classification_dict = {0: \"This tweet is from New York\", 1: \"This tweet is from London\" , 2: \"This tweet is from Paris\"}\n",
    "    return classification_dict[classifier.predict(tweet_count)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1657ac82-318a-4ed8-820f-f36d5ab6b20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This tweet is from London'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = \"I hate using the tube\"\n",
    "location_predict(tweet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
